{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distillation\n",
    "The knowledge of an elaborate, cumbersome model could be transferred to a smaller, more efficient model (faster decision-making with reduced computational costs), making it possible to deploy powerful AI in resource-constrained environments for example HFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch stock data from Yahoo Finance\n",
    "def fetch_data(stock_symbol, start_date, end_date):\n",
    "    data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
    "    return data['Close'].values  # Using closing prices\n",
    "\n",
    "# Preprocessing data to create features and labels\n",
    "def create_features_labels(data, window_size):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        x.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size] > data[i+window_size - 1])  # 1 if the price increased, else 0\n",
    "    return np.array(x), np.array(y).astype(int)\n",
    "\n",
    "# Define parameters\n",
    "stock_symbol = 'MSFT'\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2024-12-31'\n",
    "window_size = 10  # Using 10 days of stock prices to predict next day trend\n",
    "\n",
    "# Load and preprocess data\n",
    "stock_data = fetch_data(stock_symbol, start_date, end_date)\n",
    "x_train, y_train = create_features_labels(stock_data, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Teacher Model\n",
    "The model, named teacher_model, is a sequential neural network that includes dense layers with ReLU activation functions, dropout layers for regularization to prevent overfitting, and a sigmoid activation function in the output layer to predict binary outcomes (price increase or decrease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the teacher model\n",
    "teacher_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(window_size,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "teacher_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the teacher model\n",
    "teacher_model.fit(x_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Student Model\n",
    "The student model will be a simpler version of the teacher model, with fewer parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(10,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "student_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distillation\n",
    "Model distillation enables algorithmic traders to achieve high-performance trading strategies while optimizing for efficiency and flexibility in deployment, even on traditional computing resources like CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softening Predictions (Logits: These are the raw outputs from the final layer of the teacher model) with Temperature Scaling by dividing logits with parameter ð‘‡ before applying softmax.\n",
    "\n",
    "When ð‘‡>1, the softmax probabilities become more evenly distributed. If the teacher predicts [0.7, 0.3], this provides richer information for the student model, as it captures relationships between classes that hard labels (e.g., 0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soften the outputs of the teacher model\n",
    "temperature = 5.0  # Temperature hyperparameter\n",
    "teacher_predictions = teacher_model.predict(x_train)\n",
    "softened_teacher_predictions = k.nn.softmax(teacher_predictions / temperature)\n",
    "\n",
    "# Train the student model using the teacher's softened outputs\n",
    "student_model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',  # Use categorical crossentropy for softened labels\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Convert labels to categorical (since we are using softmax in teacher predictions)\n",
    "y_train_categorical = k.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "\n",
    "student_model.fit(x_train, y_train_categorical, epochs=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
